general:
  device: "cuda" if torch.cuda.is_available() else "cpu"
  seed: 42
  num_workers: 4

experiment:
  name: "CIFAR100_Analysis"
  version: 1
  description: "Multi-model ablation analysis on CIFAR100 dataset"
  save_dir: "./experiments/results"  # Base directory to save experiment-specific results
  log_dir: "./logs/tensorboard"  # Directory for storing logs
  checkpoints_dir: "./checkpoints"  # Base directory for any checkpoints
  resume_checkpoint: null  # Path to checkpoint to resume training, if needed

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  log_to_file: True
  log_to_console: True

monitoring:
  use_wandb: True
  wandb_project: "CIFAR100_Multi_Model_Analysis"
  wandb_entity: "your_entity"
  tensorboard: True

checkpointing:
  save_best_only: True
  monitor_metric: "val_loss"
  save_freq: "epoch"
  max_checkpoints: 5

early_stopping:
  enabled: True
  monitor: "val_loss"
  patience: 5
  min_delta: 0.001

hyperparameter_optimization:
  enabled: True
  optimizer: "Optuna"
  n_trials: 100
  pruner: "SuccessiveHalvingPruner"
  direction: "minimize"

evaluation:
  metrics: ["accuracy", "precision", "recall"]
  batch_size: 32
  num_workers: 4
  verbose: True

misc:
  debug: False
  use_mixed_precision: True
  deterministic: False
  additional_config: "path_to_additional_config.yaml"
