{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPCeTbube6uUEqaiXIZz4IX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZCalkins/CIFAR100-Multi-Model-Ablation-Analysis/blob/main/notebooks/cnn_ablation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "TDXi7bycWWab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93igbc4btNAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d60ade-6eee-4e89-ca15-492a32f415cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n",
            "0.17.1+cu121\n"
          ]
        }
      ],
      "source": [
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.modules.activation import LeakyReLU\n",
        "from torch.nn.modules.batchnorm import BatchNorm2d\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor, v2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# To check the versions\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Global Device Defaults"
      ],
      "metadata": {
        "id": "UoP8hjgTqfS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "torch.set_default_device(device)"
      ],
      "metadata": {
        "id": "-w25nIE0qjro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organize/Create SummaryWriters for Tensorboard"
      ],
      "metadata": {
        "id": "d9fPxNa2Eky8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_writer(experiment_name: str,\n",
        "                  model_name: str,\n",
        "                  extra: str=None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
        "\n",
        "    from datetime import datetime\n",
        "    import os\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    if extra:\n",
        "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
        "    else:\n",
        "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
        "\n",
        "    print(f\"Created SummaryWriter, saving to: {log_dir}\")\n",
        "    return SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "dZrCYyqAqNAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentations"
      ],
      "metadata": {
        "id": "5XV9bTiCi9oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_transform_flat = transforms.Compose([\n",
        "    v2.RandomResizedCrop(224),\n",
        "    v2.RandomHorizontalFlip(),\n",
        "    v2.AutoAugment(),\n",
        "    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.Lambda(lambda x: torch.flatten(x))\n",
        "])\n",
        "\n",
        "base_transform = transforms.Compose([\n",
        "    v2.RandomResizedCrop(224),\n",
        "    v2.RandomHorizontalFlip(),\n",
        "    v2.AutoAugment(),\n",
        "    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "base_transform_flat_no_augment = transforms.Compose([\n",
        "    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
        "    transforms.Lambda(lambda x: torch.flatten())\n",
        "])"
      ],
      "metadata": {
        "id": "nwwdFscwZBPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "yLDGDe2fPLKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **!!!!!!!!!!!!! CHANGE DATASETS. MAKE TRAIN DATA AND TEST DATA FOR GATED MLP (ONE DIMENSIONAL) AS WELL AS FOR ViT AND CNN ARCHITECTURES !!!!!!!!!!!!!!!!**"
      ],
      "metadata": {
        "id": "C2vij92egRNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_one_dim = datasets.CIFAR100(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=base_transform_flat_no_augment,\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "train_data_augment_one_dim = datasets.CIFAR100(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=base_transform_flat,\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "train_data_two_dim = datasets.CIFAR100(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "train_data_augment_two_dim = datasets.CIFAR100(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=base_transform,\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data_one_dim = datasets.CIFAR100(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=base_transform_flat_no_augment,\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data_two_dim = datasets.CIFAR100(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpRSsjJaPXxF",
        "outputId": "66c0d3fc-282a-4442-d85c-43aca100ab46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:12<00:00, 13014168.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data_two_dim.classes"
      ],
      "metadata": {
        "id": "ct7YPkhtQgo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoaders"
      ],
      "metadata": {
        "id": "SB2ok_GLSK1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader_one_dim = DataLoader(dataset=train_data_one_dim,\n",
        "                                      batch_size=BATCH_SIZE,\n",
        "                                      shuffle=True)\n",
        "\n",
        "train_dataloader_one_dim_augmented = DataLoader(dataset=train_data_augment_one_dim,\n",
        "                                                batch_size=BATCH_SIZE,\n",
        "                                                shuffle=True)\n",
        "\n",
        "train_dataloader_two_dim = DataLoader(dataset=train_data_augment_two_dim,\n",
        "                                      batch_size=BATCH_SIZE,\n",
        "                                      )\n",
        "\n",
        "test_dataloader_one_dim = DataLoader(dataset=test_data_one_dim,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     shuffle=False)"
      ],
      "metadata": {
        "id": "XlQxuZ3FWzz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Layer and Model Templates"
      ],
      "metadata": {
        "id": "nNLzKa4sc0n-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. CNN Architecture"
      ],
      "metadata": {
        "id": "06IniuFzaFRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Layer Configuration\n",
        "\n",
        "@dataclass\n",
        "class CNNLayerConfig:\n",
        "    in_channels: int\n",
        "    out_channels: int\n",
        "    kernel_size: int\n",
        "    stride: int = 1\n",
        "    padding: Optional[int] = None\n",
        "    use_batch_norm: bool = False\n",
        "    use_pool: bool = False\n",
        "    pool_size: Optional[int] = None\n",
        "    pool_stride: Optional[int] = None\n",
        "    pool_type: Optional[str] = None\n",
        "    use_dropout: bool = False\n",
        "    dropout_rate: Optional[float] = None\n",
        "\n",
        "# CNN Model Configuration\n",
        "\n",
        "@dataclass\n",
        "class CNNModelConfig:\n",
        "    model_name: str\n",
        "    layers: List[CNNLayerConfig] = field(default_factory=list)\n",
        "    input_shape: Tuple[int, int, int] = (3, 32, 32)\n",
        "    output_shape: int = 100\n",
        "    optimizer: str = 'adam'\n",
        "    learning_rate: float = 0.001\n",
        "    batch_size: int = 64\n",
        "    num_epochs: int = 10"
      ],
      "metadata": {
        "id": "lbjVOZ2Gmnm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. ViT Architecture"
      ],
      "metadata": {
        "id": "EYtBAEc2cmQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ViT Layer Configuration\n",
        "\n",
        "@dataclass\n",
        "class ViTLayerConfig:\n",
        "    num_heads: int\n",
        "    head_dim: int\n",
        "    mlp_dim: int\n",
        "    dropout_rate: float\n",
        "    attention_dropout_rate: float\n",
        "    use_layer_norm: bool = True\n",
        "    layer_norm_eps: Optional[float] = 1e-6\n",
        "\n",
        "# ViT Model Configuration\n",
        "\n",
        "@dataclass\n",
        "class ViTModelConfig:\n",
        "    model_name: str\n",
        "    image_size: int\n",
        "    patch_size: int\n",
        "    num_channels: int\n",
        "    hidden_dim: int\n",
        "    num_layers: int\n",
        "    num_heads: int\n",
        "    mlp_dim: int\n",
        "    num_classes: int\n",
        "    dropout_rate: float\n",
        "    attention_dropout_rate: float\n",
        "    optimizer: str = 'adam'\n",
        "    learning_rate: float = 0.001\n",
        "    batch_size: int = 64\n",
        "    num_epochs: int = 10"
      ],
      "metadata": {
        "id": "Z26dTQPucueW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Gated MLP Configuration"
      ],
      "metadata": {
        "id": "k-StfiMQdDDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gated MLP Layer Configuration\n",
        "\n",
        "@dataclass\n",
        "class GatedMLPLayerConfig:\n",
        "    input_dim: int\n",
        "    output_dim: int\n",
        "    use_gate: bool\n",
        "    dropout_rate: float\n",
        "\n",
        "# Gated MLP Model Configuration\n",
        "\n",
        "class GatedMLPModelConfig:\n",
        "    model_name: str\n",
        "    input_dim: int\n",
        "    output_dim: int\n",
        "    layers: List[GatedMLPLayerConfig] = field(default_factory=list)\n",
        "    optimizer: str = 'adam'\n",
        "    learning_rate: float = 0.001\n",
        "    batch_size: int = 64\n",
        "    num_epochs: int = 10\n",
        "    dropout_rate: float = 0.1"
      ],
      "metadata": {
        "id": "9qiYzZWqfJN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate Model, Configurations, Optimizer and Loss Function"
      ],
      "metadata": {
        "id": "Ymm5wW5xrbOr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QXhEtk9MrnjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p6-lDcaIrc2Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
